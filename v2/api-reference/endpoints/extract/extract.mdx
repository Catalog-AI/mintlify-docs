---
title: "Extract Products"
api: "POST https://api.getcatalog.ai/v2/extract"
description: "Start asynchronous product extraction from URLs or a vendor domain"
---

Start asynchronous product extraction to retrieve detailed product data. This endpoint returns immediately with an `execution_id` that you can use to check status and retrieve results.

You can extract products using one of two input sources:
- **Direct URLs:** Provide an array of product URLs to extract (up to 1000 URLs per request)
- **Vendor Domain:** Provide a vendor domain to extract products from previously discovered listings

<Note>
**Async Processing:** This endpoint starts processing asynchronously and returns an `execution_id` immediately. Use the [Get Extract Execution Status](/v2/api-reference/endpoints/extract/get-extract-status) endpoint to check progress and retrieve results when processing completes.
</Note>

<Tip>
**Managing Executions:** 
- **View All Executions:** You can view all your extraction executions using the [List Extract Executions](/v2/api-reference/endpoints/extract/list-extract-executions) endpoint to see all processing jobs, their statuses, and when they were created.
- **Cancel Running Executions:** If you need to stop a running execution, use the [Cancel Extract Execution](/v2/api-reference/endpoints/extract/cancel-extract-execution) endpoint.
</Tip>

## Request

<ParamField header="x-api-key" type="string" required>
  Your API key for authentication
</ParamField>

### Request Body

Choose one of the following input sources:

#### Input Source: Direct URLs

<ParamField body="urls" type="string[]">
  Array of product URLs to extract (1 to 1000 URLs per request). Use this when you have specific product URLs to extract.
  
  **Requirements:**
  - Must be a non-empty array
  - Each entry must be a non-empty string
  - Maximum 1000 URLs per request
  
  **Example:**
  ```json
  [
    "https://skims.com/products/cotton-jersey-long-sleeve-t-shirt-soot",
    "https://www.adidas.com/us/gazelle-shoes/BB5476.html",
    "https://www.example-store.com/product/123"
  ]
  ```
  
  **Note:** You can send a single URL in an array: `["https://example.com/product"]`
  
  **Processing:** URLs are automatically chunked into batches of 100 for efficient processing.
</ParamField>

#### Input Source: Vendor Domain

<ParamField body="vendor" type="string">
  The vendor domain to extract products from (e.g., "example.com" or "https://example.com"). Use this when you want to extract products from a vendor's previously discovered listings.
  
  **Examples:**
  - `"nike.com"`
  - `"https://www.adidas.com"`
  - `"example-store.com"`
  
  **Note:** The vendor domain will be normalized automatically. You can include or omit the protocol and www prefix.
  
  **Important:** This vendor domain must have been crawled previously using the [Crawl](/v2/api-reference/endpoints/discover/crawl) endpoint, or you must provide a `crawl_id` to wait for an active crawl to complete. Extraction requires product listings to have been discovered via crawl.
</ParamField>

#### Vendor-Specific Parameters

These parameters only apply when using the `vendor` input source:

<ParamField body="max_products" type="number" default="0">
  Maximum number of products to process. Set to `0` for no limit (process all available products).
  
  **Note:** When set to `0`, all products found in the vendor's listings will be processed. This is useful for full catalog extraction.
</ParamField>

<ParamField body="crawl_id" type="string">
  Optional crawl execution ID to wait for before starting extraction. If provided, extraction will be queued and will start automatically when the crawl execution completes.
  
  **Use Case:** Use this when you want to ensure product listings are discovered via crawl before extraction begins. The extraction will remain in `pending` status with `waiting_for` in the meta until the crawl completes.
  
  **Format:** `crawl-{vendor}-{uuid}`
  
  **Note:** If you haven't started a crawl yet, use the [Crawl](/v2/api-reference/endpoints/discover/crawl) endpoint first, then use the returned `execution_id` as the `crawl_id` parameter here.
</ParamField>

#### Shared Parameters

These parameters apply to both input sources:

<ParamField body="enable_enrichment" type="boolean" default="false">
  Whether to enable AI enrichment for products. When enabled, products are enhanced with additional attributes and categorization.
</ParamField>

<ParamField body="country_code" type="string" default="us">
  ISO 2-letter country code for localization (e.g., "us", "ca", "gb", "de")
  
  **Supported Country Codes:**
  nl, ca, si, co, by, ee, no, br, us, de, es, vn, il, th, gb, ph, kg, in, ru, fr, hk, ua, jp, at, mm, my, pl, au, nz, ro, tw, mx, id, dk, ng, ch, hu, sg, sa, ae, cn, ar, cl, it, tr, lv, gh, sk, gr, eg, lu, bg, se, lt, lk, kz, hr, bd, kr, cz, fi, ie, be, pt, za
</ParamField>

<ParamField body="enable_reviews" type="boolean" default="false">
  Whether to enable product reviews processing
</ParamField>

<ParamField body="enable_image_tags" type="boolean" default="false">
  Whether to enable AI-generated image tags and descriptions
</ParamField>

<ParamField body="regenerate_description_html" type="boolean" default="true">
  Whether to regenerate HTML-formatted product descriptions
</ParamField>

<ParamField body="populate_description_html_from_html" type="boolean" default="true">
  Whether to populate description HTML from existing HTML content
</ParamField>

<ParamField body="enable_brand_pdp" type="boolean" default="false">
  Whether to enable brand PDP (Product Detail Page) discovery for additional product information
</ParamField>

<ParamField body="enable_similar_products" type="boolean" default="false">
  Whether to enable similar products discovery to find related items
</ParamField>

<ParamField body="enable_reddit_insights" type="boolean" default="false">
  Whether to enable Reddit insights gathering for product context and discussions
</ParamField>

<ParamField body="persist_to_s3" type="boolean" default="false">
  Whether to persist results to S3 for durable storage. When enabled, results are stored in S3 in addition to being returned via the API.
</ParamField>

## Response

<ResponseField name="execution_id" type="string">
  Unique execution identifier for this extraction job. Use this ID with the [Get Extract Execution Status](/v2/api-reference/endpoints/extract/get-extract-status) endpoint to check progress and retrieve results.
  
  **Format:**
  - When using `urls`: `extract-urls-{uuid}`
  - When using `vendor`: `extract-{vendor}-{uuid}` (dots in vendor replaced with dashes)
</ResponseField>

<ResponseField name="status" type="string">
  Execution status. Will be `"pending"` in the POST response. When using `vendor` with `crawl_id`, status will be `"pending"` with `waiting_for` in meta until the crawl completes.
</ResponseField>

<ResponseField name="meta" type="object">
  Response metadata
  
  <Expandable title="Meta Properties">
    <ResponseField name="credits_used" type="number">
      Number of credits charged for this request
    </ResponseField>
    
    <ResponseField name="url_count" type="number">
      Total number of URLs submitted or found for processing
    </ResponseField>

    <ResponseField name="urls_to_process" type="number">
      Number of URLs that will actually be processed. When using `urls`, this equals `url_count`. When using `vendor`, this respects the `max_products` limit if set.
    </ResponseField>
    
    <ResponseField name="waiting_for" type="string">
      Crawl execution ID that this extraction is waiting for (only present when `crawl_id` was provided with `vendor`)
    </ResponseField>
  </Expandable>
</ResponseField>

<Note>
**HTTP Status Code:** This endpoint returns `202 Accepted` to indicate the request has been accepted for processing. The response body contains the execution details you need to track the extraction progress.
</Note>

## Response Schema and Enable Flags

The `/v2/extract` endpoint maintains a consistent response schema regardless of `enable_*` flag values. All fields are always present in product objects returned in the `data` array, but will be `null` when the corresponding flag is `false`.

**Field Mappings:**

| Flag | Affected Fields |
|------|----------------|
| `enable_reviews` | `reviews` |
| `enable_enrichment` | `attributes`, `product_type`, `google_product_category_id`, `google_product_category_path` |
| `enable_image_tags` | `images[].attributes` |
| `enable_brand_pdp` | `brand_pdp` |
| `enable_similar_products` | `similar_products` |
| `enable_reddit_insights` | `reddit_insights` |

<RequestExample>

```bash cURL (Direct URLs)
curl -X POST https://api.getcatalog.ai/v2/extract \
  -H "Content-Type: application/json" \
  -H "x-api-key: $CATALOG_API_KEY" \
  -d '{
    "urls": [
      "https://skims.com/products/cotton-jersey-long-sleeve-t-shirt-soot",
      "https://www.adidas.com/us/gazelle-shoes/BB5476.html"
    ],
    "enable_enrichment": false,
    "country_code": "us",
    "enable_reviews": false,
    "enable_image_tags": false
  }'
```

```bash cURL (Vendor Domain)
curl -X POST https://api.getcatalog.ai/v2/extract \
  -H "Content-Type: application/json" \
  -H "x-api-key: $CATALOG_API_KEY" \
  -d '{
    "vendor": "nike.com",
    "enable_enrichment": false,
    "country_code": "us",
    "max_products": 100
  }'
```

```javascript JavaScript (Direct URLs)
// Start async extraction with direct URLs
const response = await fetch('https://api.getcatalog.ai/v2/extract', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'x-api-key': 'YOUR_API_KEY'
  },
  body: JSON.stringify({
    urls: [
      'https://skims.com/products/cotton-jersey-long-sleeve-t-shirt-soot',
      'https://www.adidas.com/us/gazelle-shoes/BB5476.html'
    ],
    enable_enrichment: false,
    country_code: 'us',
    enable_reviews: false,
    enable_image_tags: false
  })
});

const { execution_id, status, meta } = await response.json();
console.log(`Execution started: ${execution_id}`);
console.log(`URLs to process: ${meta.urls_to_process}`);

// Poll for results using the execution_id
// See Get Extract Execution Status endpoint documentation for details
```

```javascript JavaScript (Vendor Domain)
// Start async extraction from vendor domain
const response = await fetch('https://api.getcatalog.ai/v2/extract', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'x-api-key': 'YOUR_API_KEY'
  },
  body: JSON.stringify({
    vendor: 'nike.com',
    enable_enrichment: false,
    country_code: 'us',
    max_products: 100
  })
});

const { execution_id, status, meta } = await response.json();
console.log(`Execution started: ${execution_id}`);
console.log(`URLs found: ${meta.url_count}`);
console.log(`URLs to process: ${meta.urls_to_process}`);

// Poll for results using the execution_id
// See Get Extract Execution Status endpoint documentation for details
```

```python Python (Direct URLs)
import requests

# Start async extraction with direct URLs
response = requests.post(
    'https://api.getcatalog.ai/v2/extract',
    headers={
        'Content-Type': 'application/json',
        'x-api-key': 'YOUR_API_KEY'
    },
    json={
        'urls': [
            'https://skims.com/products/cotton-jersey-long-sleeve-t-shirt-soot',
            'https://www.adidas.com/us/gazelle-shoes/BB5476.html'
        ],
        'enable_enrichment': False,
        'country_code': 'us',
        'enable_reviews': False,
        'enable_image_tags': False
    }
)

data = response.json()
execution_id = data['execution_id']
print(f"Execution started: {execution_id}")
print(f"URLs to process: {data['meta']['urls_to_process']}")

# Poll for results using the execution_id
# See Get Extract Execution Status endpoint documentation for details
```

```python Python (Vendor Domain)
import requests

# Start async extraction from vendor domain
response = requests.post(
    'https://api.getcatalog.ai/v2/extract',
    headers={
        'Content-Type': 'application/json',
        'x-api-key': 'YOUR_API_KEY'
    },
    json={
        'vendor': 'nike.com',
        'enable_enrichment': False,
        'country_code': 'us',
        'max_products': 100
    }
)

data = response.json()
execution_id = data['execution_id']
print(f"Execution started: {execution_id}")
print(f"URLs found: {data['meta']['url_count']}")
print(f"URLs to process: {data['meta']['urls_to_process']}")

# Poll for results using the execution_id
# See Get Extract Execution Status endpoint documentation for details
```

</RequestExample>

<ResponseExample>

```json Response (Direct URLs)
{
  "execution_id": "extract-urls-965b1912-6af0-4ed8-b7e3-184b85e788b7",
  "status": "pending",
  "meta": {
    "credits_used": 10,
    "url_count": 2,
    "urls_to_process": 2
  }
}
```

```json Response (Vendor Domain)
{
  "execution_id": "extract-nike-com-51d87084",
  "status": "pending",
  "meta": {
    "credits_used": 100,
    "url_count": 100,
    "urls_to_process": 100
  }
}
```

```json Response (Vendor Domain with crawl_id)
{
  "execution_id": "extract-nike-com-51d87084",
  "status": "pending",
  "meta": {
    "credits_used": 100,
    "url_count": 100,
    "urls_to_process": 100,
    "waiting_for": "crawl-nike-com-7f42-402f"
  }
}
```

```json Error Response (No Listings Found)
{
  "error": {
    "message": "No listings found for this domain. Use /v2/crawl first to discover product listings.",
    "code": "VALIDATION_ERROR",
    "request_id": "req-12345678-1234-1234-1234-123456789abc"
  }
}
```

</ResponseExample>

## Workflow

### Using Direct URLs

1. **Start Extraction:** Send a POST request with your `urls` array
2. **Get Execution ID:** Receive an `execution_id` immediately in the response (HTTP 202)
3. **Check Status:** Poll the [Get Extract Execution Status](/v2/api-reference/endpoints/extract/get-extract-status) endpoint using the `execution_id`
4. **Retrieve Results:** When `status` is `"completed"`, results are available with pagination support

### Using Vendor Domain

1. **Crawl the Domain (if not already done):** First, use the [Crawl](/v2/api-reference/endpoints/discover/crawl) endpoint to discover product listings from the domain. Wait for the crawl to complete or use the `crawl_id` parameter in step 2.
2. **Start Extraction:** Send a POST request with your `vendor` domain. If the domain hasn't been crawled yet, provide the `crawl_id` from step 1 to wait for crawl completion.
3. **Get Execution ID:** Receive an `execution_id` immediately in the response
4. **Check Status:** Poll the [Get Extract Execution Status](/v2/api-reference/endpoints/extract/get-extract-status) endpoint. If waiting for a crawl, the status will show `pending` with `waiting_for` in the meta.
5. **Retrieve Results:** When `status` is `"completed"`, results are available with pagination support
